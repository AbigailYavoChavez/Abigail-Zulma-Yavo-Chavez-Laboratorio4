{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Como primer punto se enlaza al drive para obtener el dataset y asi poder realizar un cuadernillo.\n",
        "El dataset que se incluye en este cuadernillo es el de \"Secuencias de proteínas estructurales\",se quiere obtener una comprensión clara y concisa de la función y relevancia del PDB en la investigación y educación en biología estructural. También se busca resaltar la importancia de los métodos utilizados para determinar las estructuras de proteínas y otras macromoléculas biológicas, así como la diversidad de información disponible en el PDB.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PmoMVNvR8kHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1iJHyAyqhjC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot\n",
        "from scipy import optimize\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta primer cuadro de codigo se importan los datos que tiene el dataset.\n"
      ],
      "metadata": {
        "id": "9ng-FxGUBIQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "VKr9E1ykqoMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de9abdb-6ead-4f7c-aa71-d0a329dcb806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AquÍ fue lo que hizo fue importacion de los dataset en el drive"
      ],
      "metadata": {
        "id": "7OgpzDO8BjL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Dataset Machine learning/train.csv\")\n",
        "data = data.fillna(0)\n",
        "data = np.array(data)\n",
        "x = data[:36800,:47]\n",
        "y = data[:36800,49]\n",
        "m_ejemplos = y.size\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "oWHTWn13qqLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190314b0-7420-4720-84db-7924ac6ba5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.179546 0.054544 0.041338 ... -3.768853 -7.064849 -44.878769]\n",
            " [0.109351 0.007854 0.006311 ... 0.001645 0.004429 0.001218]\n",
            " [0.100744 0.007863 0.0055 ... 0.008327 0.002209 0.016153]\n",
            " ...\n",
            " [0.116995 0.018328 0.032508 ... 0.007924 0.000872 -0.004522]\n",
            " [0.11473 0.013457 0.023524 ... 0.011838 0.000443 -0.010801]\n",
            " [0.110254 0.00404 0.007224 ... -0.000864 -0.000704 -0.005676]]\n",
            "[0 0 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importo la ruta de los dataset.\n",
        "Donde el array viene a ser lista de datos donde se va a convertir un vector.\n",
        "donde las variables de  \"x\" viene a ser los numeros de caracteristicas en un rango donde el numero 30 es el limite y la variable \"y\" vendria a ser lo ejemplos del dataset.\n",
        "\n",
        "Donde tambien se trabajo el 80% de los datos para entrenas y el 20% para aprobar la efectividad, como se ve mas adelante."
      ],
      "metadata": {
        "id": "NGGUks8vBwwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU8BapzrjLKw",
        "outputId": "ae595791-9424-4e12-b1c8-1b033c0db28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36800, 47)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x.shape me permite ver el indice de columnas y filas."
      ],
      "metadata": {
        "id": "_mon8dgdDj-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (x.shape[0]):\n",
        "  if (y[i] == 0):\n",
        "    y[i] = 3;"
      ],
      "metadata": {
        "id": "GzjKxF8WJ87P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f8nfABCKNUH",
        "outputId": "8cbd94af-980f-4431-93d8-198e0774a954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 3 3 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_size  = 47\n",
        "num_labels = 3\n"
      ],
      "metadata": {
        "id": "imFrvVX-vYGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "con la funcion sigmoidea, se procesa los datos para obtener un resultado entre 0 y 1"
      ],
      "metadata": {
        "id": "LI7CKpJ36C7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizarX(x):\n",
        "  x_normalizada = []\n",
        "  promedio = np.mean(x,axis=0)\n",
        "  x = x.astype(float)\n",
        "  desviacion_estandar = np.std(x,axis=0)\n",
        "  for i in range(m_ejemplos):\n",
        "    caracteristicas_x = []\n",
        "    for j in range(x.shape[1]):\n",
        "      if desviacion_estandar[j] != 0:\n",
        "        caracteristicas_x.append((x[i,j]-promedio[j])/desviacion_estandar[j])\n",
        "      else:\n",
        "        caracteristicas_x.append(0)\n",
        "    x_normalizada.append(caracteristicas_x)\n",
        "  return x_normalizada, promedio, desviacion_estandar"
      ],
      "metadata": {
        "id": "-jzF2V-KtYxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al normalizar hace que los valores sean mas pequeños.\n",
        "donde tambien saca el promedio de las colunmas de \"x\" para asi no tener valores de 0 o error."
      ],
      "metadata": {
        "id": "SfZbYRK3D4h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_normalizada, promedio, desviacion_estandar = normalizarX(x)\n",
        "x_normalizada = np.array(x_normalizada)\n",
        "x = np.concatenate((np.ones((m_ejemplos,1)),x_normalizada),axis=1)"
      ],
      "metadata": {
        "id": "fcSVC01ntZmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quí se hace las menciones de las caracteristicas para asi poderse guardar."
      ],
      "metadata": {
        "id": "hco88ShQFLqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  z = np.array(z)\n",
        "  g = np.zeros(z.shape)\n",
        "  g = 1/(1+np.exp(-z))\n",
        "  return g"
      ],
      "metadata": {
        "id": "GZgVL_XawNO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lrCostFunction(theta, x, y, lambda_):\n",
        "    if y.dtype == bool:\n",
        "        y = y.astype(int)\n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "    h = sigmoid(x.dot(theta.T))\n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "    J = (1 / m_ejemplos) * (np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))) + (lambda_ / (2 * m_ejemplos)) * np.sum(np.square(temp))\n",
        "    grad = (1 / m_ejemplos) * (h - y).dot(x)\n",
        "    grad = grad + (lambda_ / m_ejemplos) * temp\n",
        "    return J, grad"
      ],
      "metadata": {
        "id": "zl7y00BvwbDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oneVsAll(x, y, num_labels, lambda_):\n",
        "    m, n = x.shape\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "    x = np.concatenate([np.ones((m, 1)), x], axis=1)\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "        res = optimize.minimize(lrCostFunction,\n",
        "                                initial_theta,\n",
        "                                (x, (y == c), lambda_),\n",
        "                                jac=True,\n",
        "                                method='CG',\n",
        "                                options=options)\n",
        "        all_theta[c] = res.x\n",
        "    return all_theta"
      ],
      "metadata": {
        "id": "Br6TyPc5xOCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_ = 0.0001\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "all_theta = oneVsAll(x, y, num_labels, lambda_)"
      ],
      "metadata": {
        "id": "F3OuukyexgYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el costo se puede ver cada interaccion que se pueda ajustar a taza de proximidad"
      ],
      "metadata": {
        "id": "HjTb6d5uGNLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictOneVsAll(all_theta, X):\n",
        "    m = X.shape[0];\n",
        "    num_labels = all_theta.shape[0]\n",
        "    p = np.zeros(m)\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
        "    return p"
      ],
      "metadata": {
        "id": "xc3LsczepVbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "pred = predictOneVsAll(all_theta, x)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
        "XPrueba = x[10:150, :].copy()\n",
        "print(XPrueba.shape)\n",
        "XPrueba = np.concatenate([np.ones((140, 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
        "print(p)\n",
        "print(y[10:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNOohGXGpa4W",
        "outputId": "2ec6ce5b-fbfa-46a2-af76-e9e533f5bfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36800, 48)\n",
            "Precision del conjuto de entrenamiento: 32.02%\n",
            "(140, 48)\n",
            "(140, 49)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entrenar_regresion_logistica_multivariable_con_reg(X_train, y_train, tasa_aprendizaje, lambda_param, num_iteraciones):\n",
        "    m, n = X_train.shape\n",
        "    num_clases = len(np.unique(y_train))\n",
        "    X_train_con_intercepto = agregar_intercepto(X_train)  # Agregar intercepto a X_train\n",
        "\n",
        "    thetas = np.zeros((num_clases, n + 1))  # Inicializar parámetros\n",
        "\n",
        "    for clase in range(1, num_clases + 1):\n",
        "        y_binario = (y_train == clase).astype(int)\n",
        "\n",
        "        theta = thetas[clase - 1]\n",
        "\n",
        "        for i in range(num_iteraciones):\n",
        "            z = np.dot(X_train_con_intercepto, theta)\n",
        "            h = sigmoid(z)\n",
        "            error = h - y_binario\n",
        "            gradiente = np.dot(X_train_con_intercepto.T, error) / m\n",
        "            gradiente[1:] += (lambda_param / m) * theta[1:]  # Regularización, excepto para el término de intercepto\n",
        "            theta -= tasa_aprendizaje * gradiente\n",
        "\n",
        "        thetas[clase - 1] = theta\n",
        "\n",
        "    return thetas\n",
        "\n",
        "def agregar_intercepto(X):\n",
        "    m = X.shape[0]\n",
        "    intercepto = np.ones((m, 1))\n",
        "    return np.concatenate((intercepto, X), axis=1)"
      ],
      "metadata": {
        "id": "_XLmDkHZymme"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}